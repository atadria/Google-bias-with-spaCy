{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f701604a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# setup for google colab\n",
    "\n",
    "# !pip install spacy==3.1.4\n",
    "# !python -m spacy download en_core_web_md\n",
    "\n",
    "# restart runtime before running notebook  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6de9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4720b8",
   "metadata": {},
   "source": [
    "# Dependency parsing with SpaCy\n",
    "https://spacy.io/api/dependencyparser  \n",
    "https://spacy.io/usage/linguistic-features#dependency-parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b1a302",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83b1455",
   "metadata": {},
   "source": [
    "## Load and filter data\n",
    "\n",
    "Check diffrence beetween results from Google and Bing for search query: \"happy white woman\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67959a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/dataset.csv')\n",
    "dataset = df[df['query'] == 'happy+white+woman']\n",
    "dataset.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4788290",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_dataset = dataset[dataset['engine']=='google'].copy()\n",
    "bing_dataset = dataset[dataset['engine']=='bing'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ade79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Google dataset size: \", google_dataset.shape[0])\n",
    "print(\"Bing dataset size: \", bing_dataset.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccaa88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bing_dataset = bing_dataset[:78]\n",
    "print(\"Bing dataset size: \", bing_dataset.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e39c205",
   "metadata": {},
   "source": [
    "### Vizualize data\n",
    "https://amueller.github.io/word_cloud/generated/wordcloud.WordCloud.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f7daf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7134bd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(text):\n",
    "    words = []\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if token.is_alpha and not token.is_stop:\n",
    "            words.append(token.lemma_.lower())\n",
    "    return words\n",
    "\n",
    "            \n",
    "google_words = list(itertools.chain.from_iterable(google_dataset['title'].apply(get_words)))\n",
    "bing_words = list(itertools.chain.from_iterable(bing_dataset['title'].apply(get_words)))\n",
    "\n",
    "google_words_cnt = Counter(google_words)\n",
    "bing_words_cnt = Counter(bing_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea8d749",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_words_cnt.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2561de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bing_words_cnt.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b3feab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "\n",
    "def draw_word_cloud(words_cnt):\n",
    "    word_cloud = WordCloud(background_color=\"white\", width=800, height=400).fit_words(words_cnt)\n",
    "    plt.imshow(word_cloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6406db",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_word_cloud(google_words_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a6a42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_word_cloud(bing_words_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a9f11f",
   "metadata": {},
   "source": [
    "## Visualize dependencies \n",
    "https://spacy.io/usage/visualizers#dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dbd050",
   "metadata": {},
   "outputs": [],
   "source": [
    "options={'compact': True, 'distance': 90}\n",
    "\n",
    "doc = nlp('\"Happy White Woman Pregnant, Black Man. Stock Photo - Image of ...\"')\n",
    "displacy.render(doc, style=\"dep\", options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf904e61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc = nlp('\"Happy Woman With Big Smile, Studio White Background ...\"')\n",
    "displacy.render(doc, style=\"dep\", options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d2e460",
   "metadata": {},
   "source": [
    "## Get dependency and dependency heads for word 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26023073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dep_type(text, word):\n",
    "    deps = []\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if token.text.lower() == word.lower():\n",
    "            deps.append(token.dep_)\n",
    "    return deps\n",
    "\n",
    "\n",
    "def get_dep_head(text, word):\n",
    "    heads = []\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if token.text.lower() == word.lower():\n",
    "            heads.append(token.head.text.lower())\n",
    "    return heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f50f0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_dataset['deps'] = google_dataset['title'].apply(get_dep_type, word='white')\n",
    "google_dataset['deps head'] = google_dataset['title'].apply(get_dep_head, word='white')\n",
    "\n",
    "bing_dataset['deps'] = bing_dataset['title'].apply(get_dep_type, word='white')\n",
    "bing_dataset['deps head'] = bing_dataset['title'].apply(get_dep_head, word='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935fad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "deps = list(itertools.chain.from_iterable(google_dataset['deps']))\n",
    "Counter(deps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f270f5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "deps = list(itertools.chain.from_iterable(bing_dataset['deps']))\n",
    "Counter(deps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526dcb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "bing_heads = list(itertools.chain.from_iterable(bing_dataset['deps head']))\n",
    "bing_cnt = Counter(bing_heads)\n",
    "bing_cnt.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d68af43",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_heads = list(itertools.chain.from_iterable(google_dataset['deps head']))\n",
    "google_cnt = Counter(google_heads)\n",
    "google_cnt.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705d6e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = google_cnt + bing_cnt\n",
    "labels = [k for k, v in cnt.most_common(15)]\n",
    "google_values = [google_cnt[lbl] for lbl in labels]\n",
    "bing_values = [bing_cnt[lbl] for lbl in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba009a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.4\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(x-width/2, google_values, width=width, label='google')\n",
    "ax.bar(x+width/2, bing_values, width=width, label='bing')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, fontsize=15, rotation=45)\n",
    "ax.legend(fontsize=20)\n",
    "ax.set_title(\"Heads count for word 'white'\", fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d82ea8",
   "metadata": {},
   "source": [
    "## Check other queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eff50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dataset = df[df['query'] == 'happy+asian+woman'].copy()\n",
    "b_dataset = df[df['query'] == 'happy+black+woman'].copy()\n",
    "\n",
    "a_dataset['deps head'] = a_dataset['title'].apply(get_dep_head, word='asian')\n",
    "b_dataset['deps head'] = b_dataset['title'].apply(get_dep_head, word='black')\n",
    "\n",
    "a_heads = list(itertools.chain.from_iterable(a_dataset['deps head']))\n",
    "b_heads = list(itertools.chain.from_iterable(b_dataset['deps head']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e2ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_cnt = Counter(a_heads)\n",
    "a_cnt.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fceb5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_cnt = Counter(b_heads)\n",
    "b_cnt.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a02f41",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "* Check what noun phrases we can find in documents. Use doc.noun_chunks iterator.  \n",
    "https://spacy.io/api/doc#noun_chunks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
