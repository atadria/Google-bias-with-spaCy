{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb705b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for google colab\n",
    "\n",
    "# !pip install spacy==3.1.4\n",
    "# !pip install spacy-transformers\n",
    "# !python -m spacy download en_core_web_trf\n",
    "\n",
    "# restart runtime before running notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0fc041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390ddb24",
   "metadata": {},
   "source": [
    "# Transformers with SpaCy\n",
    "Pipeline based on RoBERTa: \n",
    "https://spacy.io/models/en#en_core_web_trf\n",
    "\n",
    "* [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n",
    "* [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)\n",
    "* [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5dceb2",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b220f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f20527",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = nlp(\"happy white woman\") \n",
    "doc1 = nlp(\"Happy Young  Woman In White Dress Walking In Spring Park in New York...\")\n",
    "doc2 = nlp(\"Happy Couple White Woman Black Man Stock Photo (Edit Now) 47205217\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ec588d",
   "metadata": {},
   "source": [
    "### Word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae5e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1._.trf_data.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f5c47d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query._.trf_data.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81eb96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token vectors\n",
    "query._.trf_data.tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff898d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc vector\n",
    "query._.trf_data.tensors[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a58497",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d3c975",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/dataset.csv')\n",
    "dataset = dataset[dataset['query'] == 'happy+white+woman']\n",
    "dataset = dataset.append({'title': 'happy white woman', 'engine': 'q'}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363f248e",
   "metadata": {},
   "source": [
    "### Word embeddings\n",
    "BERT based models can produce different vector representations for the same word based on context. We will use embeddings for word 'white'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb843e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vector(text, word):\n",
    "    doc = nlp(text)\n",
    "    vector = [0]*768\n",
    "    for i, token in enumerate(doc._.trf_data.tokens['input_texts'][0]):\n",
    "        if word in token.lower():\n",
    "            vector = doc._.trf_data.tensors[0][0][i]\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f933c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['vector white'] = dataset['title'].apply(get_word_vector, word='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8dbd7f",
   "metadata": {},
   "source": [
    "## Cosine similarity\n",
    "We will use cosine similaruty to compare vector representations for word 'white'.  \n",
    "https://deepai.org/machine-learning-glossary-and-terms/cosine-similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0164ce9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cos_sim(v1, v2):\n",
    "    return np.dot(v1, v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617fe438",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = dataset[dataset['engine']=='q']['vector white'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4d53cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['similarity'] = dataset['vector white'].apply(cos_sim, v2=query_vector)\n",
    "\n",
    "google_dataset = dataset[dataset['engine']=='google'][:30]\n",
    "bing_dataset = dataset[dataset['engine']=='bing'][:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfaa324",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "google_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f2d5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bing_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8855075c",
   "metadata": {},
   "source": [
    "#### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302f9a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(bing_dataset['baseline'], bing_dataset['similarity'])\n",
    "plt.scatter(google_dataset['baseline'], google_dataset['similarity'])\n",
    "plt.legend(['bing', 'google'])\n",
    "plt.xlabel(\"baseline\")\n",
    "plt.ylabel(\"similarity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed9a719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary(bing_data, google_data, query):\n",
    "    print('Similarity for word vectors')\n",
    "    print(\"\\tMean similarity for Google results (top 5): \", google_data['similarity'][:5].mean())\n",
    "    print(\"\\tMean similarity for Bing results (top 5): \", bing_data['similarity'][:5].mean())\n",
    "    print()\n",
    "    print(\"\\tMean similarity for Google results (top 30): \", google_data['similarity'].mean())\n",
    "    print(\"\\tMean similarity for Bing results (top 30): \", bing_data['similarity'].mean())\n",
    "\n",
    "    \n",
    "print_summary(bing_dataset, google_dataset, 'happy white woman')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f951e2",
   "metadata": {},
   "source": [
    "## PCA\n",
    "To reduce dimensionality we can use PCA. After reduction we can plot word embeddings on 2D scatter plot.  \n",
    "https://builtin.com/data-science/step-step-explanation-principal-component-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5164f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5f5f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "standardized = StandardScaler().fit_transform(dataset['vector white'].tolist())\n",
    "dataset[['PC 1', 'PC 2']] = pca.fit_transform(standardized)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d740b74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "google_dataset = dataset[dataset['engine']=='google']\n",
    "bing_dataset = dataset[dataset['engine']=='bing']\n",
    "query = dataset[dataset['engine']=='q']\n",
    "\n",
    "plt.scatter(bing_dataset['PC 1'], bing_dataset['PC 2'])\n",
    "plt.scatter(google_dataset['PC 1'], google_dataset['PC 2'])\n",
    "plt.scatter(query['PC 1'], query['PC 2'])\n",
    "\n",
    "plt.legend(['bing', 'google', 'query'])\n",
    "plt.xlabel(\"PC 1\")\n",
    "plt.ylabel(\"PC 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e651b545",
   "metadata": {},
   "source": [
    "## TODO: \n",
    "* Check spaCy - sentence-transformers if you want to check similarity between two documents.  \n",
    "https://spacy.io/universe/project/spacy-sentence-bert"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
